{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:04:03.660354Z","iopub.status.busy":"2023-05-16T06:04:03.659568Z","iopub.status.idle":"2023-05-16T06:04:11.363270Z","shell.execute_reply":"2023-05-16T06:04:11.362289Z","shell.execute_reply.started":"2023-05-16T06:04:03.660318Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten\n","from tensorflow.keras.optimizers import Adam, Adamax\n","from tensorflow.keras.metrics import categorical_crossentropy\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model, load_model, Sequential\n","import numpy as np\n","import pandas as pd\n","import shutil\n","import time\n","import cv2 as cv2\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import imshow\n","import os\n","import seaborn as sns\n","sns.set_style('darkgrid')\n","from PIL import Image\n","from sklearn.metrics import confusion_matrix, classification_report\n","from IPython.core.display import display, HTML"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:04:11.367345Z","iopub.status.busy":"2023-05-16T06:04:11.365296Z","iopub.status.idle":"2023-05-16T06:04:11.641543Z","shell.execute_reply":"2023-05-16T06:04:11.640507Z","shell.execute_reply.started":"2023-05-16T06:04:11.367309Z"},"trusted":true},"outputs":[],"source":["lung_dir=r'/kaggle/input/oralcancerdataset/OralCancerDataSet'\n","for i,d in enumerate([lung_dir]):\n","    filepaths=[]\n","    labels=[]\n","    classlist=os.listdir(d)\n","    for klass in classlist:\n","        classpath=os.path.join(d,klass)\n","        if os.path.isdir(classpath):\n","            flist=os.listdir(classpath)\n","            for f in flist:\n","                fpath=os.path.join(classpath,f)\n","                filepaths.append(fpath)\n","                labels.append(klass)                   \n","    Fseries= pd.Series(filepaths, name='filepaths')\n","    Lseries=pd.Series(labels, name='labels')\n","    lung_df=pd.concat([Fseries, Lseries], axis=1)\n","df=pd.concat([lung_df], axis =0).reset_index(drop=True)# make a combined dataframe\n","\n","print(df['labels'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:04:11.643417Z","iopub.status.busy":"2023-05-16T06:04:11.643094Z","iopub.status.idle":"2023-05-16T06:04:11.654713Z","shell.execute_reply":"2023-05-16T06:04:11.653515Z","shell.execute_reply.started":"2023-05-16T06:04:11.643387Z"},"trusted":true},"outputs":[],"source":["train_split=.8\n","test_split=.1\n","dummy_split=test_split/(1-train_split)\n","train_df, dummy_df=train_test_split(df, train_size=train_split, shuffle=True, random_state=123)\n","test_df, valid_df=train_test_split(dummy_df, train_size=dummy_split, shuffle=True, random_state=123)\n","print ('train_df length: ', len(train_df), ' _test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:06:14.698612Z","iopub.status.busy":"2023-05-16T06:06:14.697954Z","iopub.status.idle":"2023-05-16T06:06:16.625145Z","shell.execute_reply":"2023-05-16T06:06:16.624226Z","shell.execute_reply.started":"2023-05-16T06:06:14.698582Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","height=224\n","width=224\n","channels=3\n","batch_size=32\n","img_shape=(height, width, channels)\n","img_size=(height, width)\n","length=len(test_df)\n","test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n","test_steps=int(length/test_batch_size)\n","print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\n","def scalar(img):\n","    return img/127.5-1  # scale pixel between -1 and +1\n","gen=ImageDataGenerator(preprocessing_function=scalar)\n","train_gen=gen.flow_from_dataframe( train_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n","                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n","test_gen=gen.flow_from_dataframe( test_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n","                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n","valid_gen=gen.flow_from_dataframe( valid_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n","                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n","classes=list(train_gen.class_indices.keys())\n","class_count=len(classes)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:06:16.627298Z","iopub.status.busy":"2023-05-16T06:06:16.626777Z","iopub.status.idle":"2023-05-16T06:06:16.634174Z","shell.execute_reply":"2023-05-16T06:06:16.633201Z","shell.execute_reply.started":"2023-05-16T06:06:16.627265Z"},"trusted":true},"outputs":[],"source":["def print_in_color(txt_msg,fore_tupple,back_tupple,):\n","    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n","    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n","    rf,gf,bf=fore_tupple\n","    rb,gb,bb=back_tupple\n","    msg='{0}' + txt_msg\n","    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n","    print(msg .format(mat), flush=True)\n","    print('\\33[0m', flush=True) # returns default print color to back to black\n","    return"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:06:17.954827Z","iopub.status.busy":"2023-05-16T06:06:17.954452Z","iopub.status.idle":"2023-05-16T06:06:17.980281Z","shell.execute_reply":"2023-05-16T06:06:17.978806Z","shell.execute_reply.started":"2023-05-16T06:06:17.954782Z"},"trusted":true},"outputs":[],"source":["class LRA(keras.callbacks.Callback):\n","    reset=False\n","    count=0\n","    stop_count=0\n","    tepochs=0\n","    def __init__(self,model, patience,stop_patience, threshold, factor, dwell, model_name, freeze, initial_epoch):\n","        super(LRA, self).__init__()\n","        self.model=model\n","        self.patience=patience # specifies how many epochs without improvement before learning rate is adjusted\n","        self.stop_patience=stop_patience\n","        self.threshold=threshold # specifies training accuracy threshold when lr will be adjusted based on validation loss\n","        self.factor=factor # factor by which to reduce the learning rate\n","        self.dwell=dwell\n","        self.lr=float(tf.keras.backend.get_value(model.optimizer.lr)) # get the initiallearning rate and save it in self.lr\n","        self.highest_tracc=0.0 # set highest training accuracy to 0\n","        self.lowest_vloss=np.inf # set lowest validation loss to infinity\n","        #self.count=0 # initialize counter that counts epochs with no improvement\n","        #self.stop_count=0 # initialize counter that counts how manytimes lr has been adjustd with no improvement  \n","        self.initial_epoch=initial_epoch \n","        #self.epochs=epochs\n","        best_weights=self.model.get_weights() # set a class vaiable so weights can be loaded after training is completed        \n","        msg=' '\n","        if freeze==True:\n","            msgs=f' Starting training using  base model { model_name} with weights frozen to imagenet weights initializing LRA callback'\n","        else:\n","            msgs=f' Starting training using base model { model_name} training all layers '            \n","        print_in_color (msgs, (244, 252, 3), (55,65,80)) \n","        \n","    def on_epoch_begin(self,epoch, logs=None):\n","        self.now= time.time()\n","        \n","    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n","        later=time.time()\n","        duration=later-self.now        \n","        if epoch== self.initial_epoch or LRA.reset==True:  \n","            LRA.reset=False           \n","            msg='{0:^8s}{1:^10s}{2:^9s}{3:^9s}{4:^9s}{5:^9s}{6:^9s}{7:^11s}{8:^8s}'.format('Epoch', 'Loss', 'Accuracy','V_loss','V_acc', 'LR', 'Next LR', 'Monitor', 'Duration')\n","            print_in_color(msg, (244,252,3), (55,65,80)) \n","            \n","        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n","        current_lr=lr\n","        v_loss=logs.get('val_loss')  # get the validation loss for this epoch\n","        acc=logs.get('accuracy')  # get training accuracy \n","        v_acc=logs.get('val_accuracy')\n","        loss=logs.get('loss')\n","        #print ( '\\n',v_loss, self.lowest_vloss, acc, self.highest_tracc)\n","        if acc < self.threshold: # if training accuracy is below threshold adjust lr based on training accuracy\n","            monitor='accuracy'\n","            if acc>self.highest_tracc: # training accuracy improved in the epoch                \n","                self.highest_tracc=acc # set new highest training accuracy\n","                LRA.best_weights=self.model.get_weights() # traing accuracy improved so save the weights\n","                self.count=0 # set count to 0 since training accuracy improved\n","                self.stop_count=0 # set stop counter to 0\n","                if v_loss<self.lowest_vloss:\n","                    self.lowest_vloss=v_loss\n","                color= (0,255,0)\n","                self.lr=lr\n","            else: \n","                # training accuracy did not improve check if this has happened for patience number of epochs\n","                # if so adjust learning rate\n","                if self.count>=self.patience -1:\n","                    color=(245, 170, 66)\n","                    self.lr= lr* self.factor # adjust the learning by factor\n","                    tf.keras.backend.set_value(self.model.optimizer.lr, self.lr) # set the learning rate in the optimizer\n","                    self.count=0 # reset the count to 0\n","                    self.stop_count=self.stop_count + 1\n","                    if self.dwell:\n","                        self.model.set_weights(LRA.best_weights) # return to better point in N space                        \n","                    else:\n","                        if v_loss<self.lowest_vloss:\n","                            self.lowest_vloss=v_loss                                    \n","                else:\n","                    self.count=self.count +1 # increment patience counter                    \n","        else: # training accuracy is above threshold so adjust learning rate based on validation loss\n","            monitor='val_loss'\n","            if v_loss< self.lowest_vloss: # check if the validation loss improved \n","                self.lowest_vloss=v_loss # replace lowest validation loss with new validation loss                \n","                LRA.best_weights=self.model.get_weights() # validation loss improved so save the weights\n","                self.count=0 # reset count since validation loss improved  \n","                self.stop_count=0  \n","                color=(0,255,0)\n","                self.lr=lr\n","            else: # validation loss did not improve\n","                if self.count>=self.patience-1:\n","                    color=(245, 170, 66)\n","                    self.lr=self.lr * self.factor # adjust the learning rate\n","                    self.stop_count=self.stop_count + 1 # increment stop counter because lr was adjusted \n","                    self.count=0 # reset counter\n","                    tf.keras.backend.set_value(self.model.optimizer.lr, self.lr) # set the learning rate in the optimizer\n","                    if self.dwell:\n","                        self.model.set_weights(LRA.best_weights) # return to better point in N space\n","                else: \n","                    self.count =self.count +1 # increment the patience counter                    \n","                if acc>self.highest_tracc:\n","                    self.highest_tracc= acc\n","        msg=f'{str(epoch+1):^3s}/{str(LRA.tepochs):4s} {loss:^9.3f}{acc*100:^9.3f}{v_loss:^9.5f}{v_acc*100:^9.3f}{current_lr:^9.5f}{self.lr:^9.5f}{monitor:^11s}{duration:^8.2f}'\n","        print_in_color (msg,color, (55,65,80))\n","        if self.stop_count> self.stop_patience - 1: # check if learning rate has been adjusted stop_count times with no improvement\n","            msg=f' training has been halted at epoch {epoch + 1} after {self.stop_patience} adjustments of learning rate with no improvement'\n","            print_in_color(msg, (0,255,0), (55,65,80))\n","            self.model.stop_training = True # stop training"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:06:19.338730Z","iopub.status.busy":"2023-05-16T06:06:19.338383Z","iopub.status.idle":"2023-05-16T06:06:19.354920Z","shell.execute_reply":"2023-05-16T06:06:19.353957Z","shell.execute_reply.started":"2023-05-16T06:06:19.338702Z"},"trusted":true},"outputs":[],"source":["%load_ext tensorboard\n","import tensorflow as tf\n","import datetime, os\n","%reload_ext tensorboard"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:06:20.280921Z","iopub.status.busy":"2023-05-16T06:06:20.280548Z","iopub.status.idle":"2023-05-16T06:06:20.297236Z","shell.execute_reply":"2023-05-16T06:06:20.296318Z","shell.execute_reply.started":"2023-05-16T06:06:20.280889Z"},"trusted":true},"outputs":[],"source":["def tr_plot(tr_data, start_epoch,p,r):\n","    #Plot the training and validation data\n","    tacc = tr_data.history['accuracy']\n","    tloss = tr_data.history['loss']\n","    tpre = tr_data.history[p]\n","    trec = tr_data.history[r]\n","    vacc = tr_data.history['val_accuracy']\n","    vloss = tr_data.history['val_loss']\n","    vpre = tr_data.history['val_'+p]\n","    vrec = tr_data.history['val_'+r]\n","    Epoch_count = len(tacc) + start_epoch\n","    Epochs = []\n","    for i in range(start_epoch, Epoch_count):\n","        Epochs.append(i + 1)\n","    index_loss = np.argmin(vloss) # this is the epoch with the lowest validation loss\n","    val_lowest = vloss[index_loss]\n","    index_acc = np.argmax(vacc)\n","    acc_highest = vacc[index_acc]\n","    plt.style.use('fivethirtyeight')\n","    sc_label = 'best epoch= ' + str(index_loss + 1 + start_epoch)\n","    vc_label = 'best epoch= ' + str(index_acc + 1 + start_epoch)\n","    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 16))\n","    \n","    # Loss and accuracy plots\n","    axes[0][0].plot(Epochs, tloss, 'r', label='Training loss')\n","    axes[0][0].plot(Epochs, vloss,'g',label='Validation loss' )\n","    axes[0][0].scatter(index_loss + 1 + start_epoch, val_lowest, s=150, c='blue', label=sc_label)\n","    axes[0][0].set_title('Training and Validation Loss')\n","    axes[0][0].set_xlabel('Epochs')\n","    axes[0][0].set_ylabel('Loss')\n","    axes[0][0].legend()\n","    \n","    axes[0][1].plot(Epochs, tacc,'r',label='Training Accuracy')\n","    axes[0][1].plot(Epochs, vacc,'g',label='Validation Accuracy')\n","    axes[0][1].scatter(index_acc + 1 + start_epoch, acc_highest, s=150, c='blue', label=vc_label)\n","    axes[0][1].set_title('Training and Validation Accuracy')\n","    axes[0][1].set_xlabel('Epochs')\n","    axes[0][1].set_ylabel('Accuracy')\n","    axes[0][1].legend()\n","    \n","    # Precision and recall plots\n","    axes[1][0].plot(Epochs, tpre,'r',label='Training Precision')\n","    axes[1][0].plot(Epochs, vpre,'g',label='Validation Precision')\n","    axes[1][0].set_title('Training and Validation Precision')\n","    axes[1][0].set_xlabel('Epochs')\n","    axes[1][0].set_ylabel('Precision')\n","    axes[1][0].legend()\n","    \n","    axes[1][1].plot(Epochs, trec,'r',label='Training Recall')\n","    axes[1][1].plot(Epochs, vrec,'g',label='Validation Recall')\n","    axes[1][1].set_title('Training and Validation Recall')\n","    axes[1][1].set_xlabel('Epochs')\n","    axes[1][1].set_ylabel('Recall')\n","    axes[1][1].legend()\n","    \n","    plt.tight_layout()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:06:21.512563Z","iopub.status.busy":"2023-05-16T06:06:21.511971Z","iopub.status.idle":"2023-05-16T06:06:21.535885Z","shell.execute_reply":"2023-05-16T06:06:21.534746Z","shell.execute_reply.started":"2023-05-16T06:06:21.512528Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import roc_curve, auc\n","import matplotlib.pyplot as plt\n","import numpy as np\n","def print_info( test_gen, preds, print_code, save_dir, subject ):\n","    class_dict=test_gen.class_indices\n","    labels= test_gen.labels\n","    file_names= test_gen.filenames \n","    error_list=[]\n","    true_class=[]\n","    pred_class=[]\n","    prob_list=[]\n","    new_dict={}\n","    error_indices=[]\n","    y_pred=[]\n","    for key,value in class_dict.items():\n","        new_dict[value]=key             # dictionary {integer of class number: string of class name}\n","    # store new_dict as a text fine in the save_dir\n","    classes=list(new_dict.values())     # list of string of class names\n","    dict_as_text=str(new_dict)\n","    dict_name= subject + '-' +str(len(classes)) +'.txt'  \n","    dict_path=os.path.join(save_dir,dict_name)    \n","    with open(dict_path, 'w') as x_file:\n","        x_file.write(dict_as_text)    \n","    errors=0      \n","    for i, p in enumerate(preds):\n","        pred_index=np.argmax(p)        \n","        true_index=labels[i]  # labels are integer values\n","        if pred_index != true_index: # a misclassification has occurred\n","            error_list.append(file_names[i])\n","            true_class.append(new_dict[true_index])\n","            pred_class.append(new_dict[pred_index])\n","            prob_list.append(p[pred_index])\n","            error_indices.append(true_index)            \n","            errors=errors + 1\n","        y_pred.append(pred_index)    \n","    if print_code !=0:\n","        if errors>0:\n","            if print_code>errors:\n","                r=errors\n","            else:\n","                r=print_code           \n","            msg='{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class' , 'True Class', 'Probability')\n","            print_in_color(msg, (0,255,0),(55,65,80))\n","            for i in range(r):                \n","                split1=os.path.split(error_list[i])                \n","                split2=os.path.split(split1[0])                \n","                fname=split2[1] + '/' + split1[1]\n","                msg='{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(fname, pred_class[i],true_class[i], ' ', prob_list[i])\n","                print_in_color(msg, (255,255,255), (55,65,60))\n","                #print(error_list[i]  , pred_class[i], true_class[i], prob_list[i])               \n","        else:\n","            msg='With accuracy of 100 % there are no errors to print'\n","            print_in_color(msg, (0,255,0),(55,65,80))\n","    if errors>0:\n","        plot_bar=[]\n","        plot_class=[]\n","        for  key, value in new_dict.items():        \n","            count=error_indices.count(key) \n","            if count!=0:\n","                plot_bar.append(count) # list containg how many times a class c had an error\n","                plot_class.append(value)   # stores the class \n","        fig=plt.figure()\n","        fig.set_figheight(len(plot_class)/3)\n","        fig.set_figwidth(10)\n","        plt.style.use('fivethirtyeight')\n","        for i in range(0, len(plot_class)):\n","            c=plot_class[i]\n","            x=plot_bar[i]\n","            plt.barh(c, x, )\n","            plt.title( ' Errors by Class on Test Set')\n","    y_true= np.array(labels)        \n","    y_pred=np.array(y_pred)\n","    if len(classes)<= 30:\n","        # create a confusion matrix \n","        cm = confusion_matrix(y_true, y_pred )        \n","        length=len(classes)\n","        if length<8:\n","            fig_width=8\n","            fig_height=8\n","        else:\n","            fig_width= int(length * .5)\n","            fig_height= int(length * .5)\n","        plt.figure(figsize=(fig_width, fig_height))\n","        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n","        plt.xticks(np.arange(length)+.5, classes, rotation= 90)\n","        plt.yticks(np.arange(length)+.5, classes, rotation=0)\n","        plt.xlabel(\"Predicted\")\n","        plt.ylabel(\"Actual\")\n","        plt.title(\"Confusion Matrix\")\n","        plt.show()\n","\n","    # Assuming you have your test data and predicted scores in y_test and y_pred respectively\n","    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n","\n","    # Calculate AUC (Area Under the Curve)\n","    roc_auc = auc(fpr, tpr)\n","\n","    # Plot ROC curve\n","    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], 'k--') # Plot diagonal line\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic (ROC) Curve')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()\n","\n","    clr = classification_report(y_true, y_pred, target_names=classes)\n","    print(\"Classification Report:\\n----------------------\\n\", clr)"]},{"cell_type":"markdown","metadata":{},"source":["# **VGG19**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:06:26.512829Z","iopub.status.busy":"2023-05-16T06:06:26.512469Z","iopub.status.idle":"2023-05-16T06:06:32.744020Z","shell.execute_reply":"2023-05-16T06:06:32.743098Z","shell.execute_reply.started":"2023-05-16T06:06:26.512788Z"},"trusted":true},"outputs":[],"source":["from keras.applications.vgg19 import VGG19\n","from keras.metrics import Recall,Precision\n","model_name='VGG19'\n","base_model = VGG19(input_shape=(224, 224, 3), weights='imagenet', pooling=\"avg\", include_top=False)\n","x=base_model.output\n","x=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n","x = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n","                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\n","x=Dropout(rate=.45, seed=123)(x)        \n","output=Dense(class_count, activation='softmax')(x)\n","model=Model(inputs=base_model.input, outputs=output)\n","model.compile(Adamax(lr=.001), loss='categorical_crossentropy', metrics=['accuracy',Precision(),Recall()])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:06:32.745935Z","iopub.status.busy":"2023-05-16T06:06:32.745601Z","iopub.status.idle":"2023-05-16T06:11:04.519392Z","shell.execute_reply":"2023-05-16T06:11:04.518410Z","shell.execute_reply.started":"2023-05-16T06:06:32.745902Z"},"trusted":true},"outputs":[],"source":["epochs =10\n","patience= 1 # number of epochs to wait to adjust lr if monitored value does not improve\n","stop_patience =3 # number of epochs to wait before stopping training if monitored value does not improve\n","threshold=.9 # if train accuracy is < threshhold adjust monitor accuracy, else monitor validation loss\n","factor=.5 # factor to reduce lr by\n","dwell=True # experimental, if True and monitored metric does not improve on current epoch set  modelweights back to weights of previous epoch\n","freeze=False # if true free weights of  the base model\n","logdir = os.path.join(\"logs/Adamax\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n","callbacks=[LRA(model=model,patience=patience,stop_patience=stop_patience, threshold=threshold,\n","                   factor=factor,dwell=dwell, model_name=model_name, freeze=freeze, initial_epoch=0 ),tensorboard_callback]\n","LRA.tepochs=epochs  # used to determine value of last epoch for printing\n","history=model.fit(x=train_gen,  epochs=epochs, callbacks=callbacks, verbose=0,  validation_data=valid_gen,\n","               validation_steps=None,  shuffle=False,  initial_epoch=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:12:12.227972Z","iopub.status.busy":"2023-05-16T06:12:12.227592Z","iopub.status.idle":"2023-05-16T06:12:21.610416Z","shell.execute_reply":"2023-05-16T06:12:21.608572Z","shell.execute_reply.started":"2023-05-16T06:12:12.227942Z"},"trusted":true},"outputs":[],"source":["tr_plot(history,0,'precision','recall')\n","save_dir=r'./'\n","subject='fruits'\n","acc=model.evaluate( test_gen, batch_size=test_batch_size, verbose=1, steps=test_steps, return_dict=False)[1]*100\n","msg=f'accuracy on the test set is {acc:5.2f} %'\n","print_in_color(msg, (0,255,0),(55,65,80))\n","save_id=str (model_name +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\n","save_loc=os.path.join(save_dir, save_id)\n","model.save(save_loc)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:12:24.685879Z","iopub.status.busy":"2023-05-16T06:12:24.685479Z","iopub.status.idle":"2023-05-16T06:12:27.181395Z","shell.execute_reply":"2023-05-16T06:12:27.180510Z","shell.execute_reply.started":"2023-05-16T06:12:24.685807Z"},"trusted":true},"outputs":[],"source":["print_code=0\n","preds=model.predict(test_gen) \n","print_info( test_gen, preds, print_code, save_dir, subject )  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# RESNET50"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:12:32.407121Z","iopub.status.busy":"2023-05-16T06:12:32.406746Z","iopub.status.idle":"2023-05-16T06:12:38.159063Z","shell.execute_reply":"2023-05-16T06:12:38.157938Z","shell.execute_reply.started":"2023-05-16T06:12:32.407090Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.applications.resnet50 import ResNet50\n","model_name1='ResNet50'\n","base_model1 = ResNet50(input_shape=(224, 224, 3), weights='imagenet', pooling=\"avg\", include_top=False)\n","x1=base_model1.output\n","x1=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x1)\n","x1 = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n","                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x1)\n","x1=Dropout(rate=.45, seed=123)(x1)        \n","output1=Dense(class_count, activation='softmax')(x1)\n","model1=Model(inputs=base_model1.input, outputs=output1)\n","model1.compile(Adamax(lr=.001), loss='categorical_crossentropy', metrics=['accuracy',Precision(),Recall()])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:12:38.161253Z","iopub.status.busy":"2023-05-16T06:12:38.160913Z","iopub.status.idle":"2023-05-16T06:16:41.642893Z","shell.execute_reply":"2023-05-16T06:16:41.641871Z","shell.execute_reply.started":"2023-05-16T06:12:38.161220Z"},"trusted":true},"outputs":[],"source":["logdir1 = os.path.join(\"logs/Adamax\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback1 = tf.keras.callbacks.TensorBoard(logdir1, histogram_freq=1)\n","callbacks1=[LRA(model=model1,patience=patience,stop_patience=stop_patience, threshold=threshold,\n","                   factor=factor,dwell=dwell, model_name=model_name1, freeze=freeze, initial_epoch=0 ),tensorboard_callback1]\n","LRA.tepochs=epochs  # used to determine value of last epoch for printing\n","history1=model1.fit(x=train_gen,  epochs=epochs, callbacks=callbacks1, verbose=0,  validation_data=valid_gen,\n","               validation_steps=None,  shuffle=False,  initial_epoch=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:16:41.645307Z","iopub.status.busy":"2023-05-16T06:16:41.645021Z","iopub.status.idle":"2023-05-16T06:16:47.077807Z","shell.execute_reply":"2023-05-16T06:16:47.076732Z","shell.execute_reply.started":"2023-05-16T06:16:41.645282Z"},"trusted":true},"outputs":[],"source":["tr_plot(history1,0,'precision_1','recall_1')\n","save_dir=r'./'\n","subject='fruits'\n","acc=model1.evaluate( test_gen, batch_size=test_batch_size, verbose=1, steps=test_steps, return_dict=False)[1]*100\n","msg=f'accuracy on the test set is {acc:5.2f} %'\n","print_in_color(msg, (0,255,0),(55,65,80))\n","save_id=str (model_name1 +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\n","save_loc1=os.path.join(save_dir, save_id)\n","model1.save(save_loc1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:16:47.079764Z","iopub.status.busy":"2023-05-16T06:16:47.079395Z","iopub.status.idle":"2023-05-16T06:16:50.178608Z","shell.execute_reply":"2023-05-16T06:16:50.177559Z","shell.execute_reply.started":"2023-05-16T06:16:47.079730Z"},"trusted":true},"outputs":[],"source":["print_code=0\n","preds1=model1.predict(test_gen) \n","print_info( test_gen, preds1, print_code, save_dir, subject )  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# INCEPTIONV3"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:22:36.938891Z","iopub.status.busy":"2023-05-16T06:22:36.937902Z","iopub.status.idle":"2023-05-16T06:22:43.095935Z","shell.execute_reply":"2023-05-16T06:22:43.095037Z","shell.execute_reply.started":"2023-05-16T06:22:36.938845Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.applications.inception_v3 import InceptionV3\n","model_name2='InceptionV3'\n","base_model2 = InceptionV3(input_shape=(224, 224, 3), weights='imagenet', pooling=\"avg\", include_top=False)\n","x2=base_model2.output\n","x2=keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x2)\n","x2 = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n","                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x2)\n","x2=Dropout(rate=.45, seed=123)(x2)        \n","output2=Dense(class_count, activation='softmax')(x2)\n","model2=Model(inputs=base_model2.input, outputs=output2)\n","model2.compile(Adamax(lr=.001), loss='categorical_crossentropy', metrics=['accuracy',Precision(),Recall()])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:24:20.239309Z","iopub.status.busy":"2023-05-16T06:24:20.238943Z","iopub.status.idle":"2023-05-16T06:28:01.896970Z","shell.execute_reply":"2023-05-16T06:28:01.895887Z","shell.execute_reply.started":"2023-05-16T06:24:20.239279Z"},"trusted":true},"outputs":[],"source":["logdir2 = os.path.join(\"logs2/Adamax\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback2 = tf.keras.callbacks.TensorBoard(logdir2, histogram_freq=1)\n","callbacks2=[LRA(model=model2,patience=patience,stop_patience=stop_patience, threshold=threshold,\n","                   factor=factor,dwell=dwell, model_name=model_name2, freeze=freeze, initial_epoch=0 ),tensorboard_callback2]\n","LRA.tepochs=epochs  # used to determine value of last epoch for printing\n","history2=model2.fit(x=train_gen,  epochs=epochs, callbacks=callbacks2, verbose=0,  validation_data=valid_gen,\n","               validation_steps=None,  shuffle=False,  initial_epoch=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:28:01.899279Z","iopub.status.busy":"2023-05-16T06:28:01.898915Z","iopub.status.idle":"2023-05-16T06:28:07.903149Z","shell.execute_reply":"2023-05-16T06:28:07.902260Z","shell.execute_reply.started":"2023-05-16T06:28:01.899246Z"},"trusted":true},"outputs":[],"source":["tr_plot(history2,0,'precision_2','recall_2')\n","save_dir=r'./'\n","subject='fruits'\n","acc=model2.evaluate( test_gen, batch_size=test_batch_size, verbose=1, steps=test_steps, return_dict=False)[1]*100\n","msg=f'accuracy on the test set is {acc:5.2f} %'\n","print_in_color(msg, (0,255,0),(55,65,80))\n","save_id=str (model_name2 +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\n","save_loc2=os.path.join(save_dir, save_id)\n","model2.save(save_loc2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:28:07.905239Z","iopub.status.busy":"2023-05-16T06:28:07.904447Z","iopub.status.idle":"2023-05-16T06:28:11.284905Z","shell.execute_reply":"2023-05-16T06:28:11.283585Z","shell.execute_reply.started":"2023-05-16T06:28:07.905204Z"},"trusted":true},"outputs":[],"source":["print_code=0\n","preds2=model2.predict(test_gen) \n","print_info( test_gen, preds2, print_code, save_dir, subject ) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# ENSEMBLE_MODEL"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:28:11.288613Z","iopub.status.busy":"2023-05-16T06:28:11.288157Z","iopub.status.idle":"2023-05-16T06:28:19.564487Z","shell.execute_reply":"2023-05-16T06:28:19.563488Z","shell.execute_reply.started":"2023-05-16T06:28:11.288572Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input, Average\n","model_1 = load_model(save_loc)\n","model_1 = Model(inputs=model_1.inputs,\n","                outputs=model_1.outputs,\n","                name='name_of_model_1')\n","model_2 = load_model(save_loc1)\n","model_2 = Model(inputs=model_2.inputs,\n","                outputs=model_2.outputs,\n","                name='name_of_model_2')\n","model_3 = load_model(save_loc2)\n","model_3 = Model(inputs=model_3.inputs,\n","                outputs=model_3.outputs,\n","                name='name_of_model_3')\n","\n","models = [model_1, model_2,model_3]\n","model_input = Input(shape=(224, 224, 3))\n","model_outputs = [model(model_input) for model in models]\n","ensemble_output = Average()(model_outputs)\n","ensemble_model = Model(inputs=model_input, outputs=ensemble_output, name='ensemble')\n","\n","# ensemble_model.compile(optimizer='adam',loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),metrics=['accuracy',Precision(),Recall()])\n","ensemble_model.compile(Adamax(lr=.001), loss='categorical_crossentropy', metrics=['accuracy',Precision(),Recall()])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:28:19.566224Z","iopub.status.busy":"2023-05-16T06:28:19.565871Z","iopub.status.idle":"2023-05-16T06:39:41.974861Z","shell.execute_reply":"2023-05-16T06:39:41.973876Z","shell.execute_reply.started":"2023-05-16T06:28:19.566189Z"},"trusted":true},"outputs":[],"source":["model_name3 = 'Ensemble_model'\n","logdir3 = os.path.join(\"logs3/Adamax\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback3 = tf.keras.callbacks.TensorBoard(logdir3, histogram_freq=1)\n","callbacks3=[LRA(model=ensemble_model,patience=patience,stop_patience=stop_patience, threshold=threshold,\n","                   factor=factor,dwell=dwell, model_name=model_name3, freeze=freeze, initial_epoch=0 ),tensorboard_callback3]\n","LRA.tepochs=epochs  # used to determine value of last epoch for printing\n","history3=ensemble_model.fit(x=train_gen,  epochs=epochs, callbacks=callbacks3, verbose=0,  validation_data=valid_gen,\n","               validation_steps=None,  shuffle=False,  initial_epoch=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:42:02.833912Z","iopub.status.busy":"2023-05-16T06:42:02.833524Z","iopub.status.idle":"2023-05-16T06:42:10.871894Z","shell.execute_reply":"2023-05-16T06:42:10.870953Z","shell.execute_reply.started":"2023-05-16T06:42:02.833879Z"},"trusted":true},"outputs":[],"source":["tr_plot(history3,0,'precision_3','recall_3')\n","save_dir=r'./'\n","subject='fruits'\n","acc=ensemble_model.evaluate( test_gen, batch_size=test_batch_size, verbose=1, steps=test_steps, return_dict=False)[1]*100\n","msg=f'accuracy on the test set is {acc:5.2f} %'\n","print_in_color(msg, (0,255,0),(55,65,80))\n","save_id=str (model_name3 +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\n","save_loc3=os.path.join(save_dir, save_id)\n","ensemble_model.save(save_loc3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:42:10.878537Z","iopub.status.busy":"2023-05-16T06:42:10.873789Z","iopub.status.idle":"2023-05-16T06:42:16.197537Z","shell.execute_reply":"2023-05-16T06:42:16.196528Z","shell.execute_reply.started":"2023-05-16T06:42:10.878490Z"},"trusted":true},"outputs":[],"source":["print_code=0\n","preds3=ensemble_model.predict(test_gen) \n","print_info( test_gen, preds3, print_code, save_dir, subject ) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Feature Mapping"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:44:15.081173Z","iopub.status.busy":"2023-05-16T06:44:15.080698Z","iopub.status.idle":"2023-05-16T06:44:19.094762Z","shell.execute_reply":"2023-05-16T06:44:19.093739Z","shell.execute_reply.started":"2023-05-16T06:44:15.081133Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n","from tensorflow.keras.models import Model\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","model = load_model(save_loc)\n","\n","# Load Vgg19 model\n","# Select the layer to visualize\n","layer_name = 'block5_conv4'\n","\n","# Create a new model that outputs the selected layer feature maps\n","layer_output = model.get_layer(layer_name).output\n","new_model = Model(inputs=model.input, outputs=layer_output)\n","\n","# Load and preprocess the image\n","img_path = '/kaggle/input/oralcancerdataset/OralCancerDataSet/Cancer/C (264).jpg'\n","img = image.load_img(img_path, target_size=(224, 224))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)\n","\n","# Get the feature maps for the input image\n","feature_maps = new_model.predict(x)\n","\n","# Plot the feature maps\n","ix = 1\n","for _ in range(8):\n","    for _ in range(8):\n","        # define subplot\n","        ax = plt.subplot(8, 8, ix)\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        # plot filter channel in grayscale\n","        plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n","        ix += 1\n","# show the figure\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:44:24.475801Z","iopub.status.busy":"2023-05-16T06:44:24.475430Z","iopub.status.idle":"2023-05-16T06:44:31.549937Z","shell.execute_reply":"2023-05-16T06:44:31.548837Z","shell.execute_reply.started":"2023-05-16T06:44:24.475773Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n","from tensorflow.keras.models import Model\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","model = load_model(save_loc1)\n","\n","# Load ResNet50 model\n","# Select the layer to visualize\n","layer_name = 'conv5_block3_3_conv'\n","\n","# Create a new model that outputs the selected layer feature maps\n","layer_output = model.get_layer(layer_name).output\n","new_model = Model(inputs=model.input, outputs=layer_output)\n","\n","# Load and preprocess the image\n","img_path = '/kaggle/input/oralcancerdataset/OralCancerDataSet/Cancer/C (264).jpg'\n","img = image.load_img(img_path, target_size=(224, 224))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)\n","\n","# Get the feature maps for the input image\n","feature_maps = new_model.predict(x)\n","\n","# Plot the feature maps\n","ix = 1\n","for _ in range(8):\n","    for _ in range(8):\n","        # define subplot\n","        ax = plt.subplot(8, 8, ix)\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        # plot filter channel in grayscale\n","        plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n","        ix += 1\n","# show the figure\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-16T06:45:27.946150Z","iopub.status.busy":"2023-05-16T06:45:27.945764Z","iopub.status.idle":"2023-05-16T06:45:35.233742Z","shell.execute_reply":"2023-05-16T06:45:35.232840Z","shell.execute_reply.started":"2023-05-16T06:45:27.946118Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n","from tensorflow.keras.models import Model\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","model = load_model(save_loc2)\n","\n","# Load InceptionV3 model\n","# Select the layer to visualize\n","layer_name = 'conv2d_93'\n","\n","# Create a new model that outputs the selected layer feature maps\n","layer_output = model.get_layer(layer_name).output\n","new_model = Model(inputs=model.input, outputs=layer_output)\n","\n","# Load and preprocess the image\n","img_path = '/kaggle/input/oralcancerdataset/OralCancerDataSet/Cancer/C (264).jpg'\n","img = image.load_img(img_path, target_size=(224, 224))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)\n","\n","# Get the feature maps for the input image\n","feature_maps = new_model.predict(x)\n","\n","# Plot the feature maps\n","ix = 1\n","for _ in range(8):\n","    for _ in range(8):\n","        # define subplot\n","        ax = plt.subplot(8, 8, ix)\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        # plot filter channel in grayscale\n","        plt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n","        ix += 1\n","# show the figure\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
